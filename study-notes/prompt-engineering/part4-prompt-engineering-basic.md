# Part 4. 프롬프트 엔지니어링 기초 지식

## Chapter 1. 프롬프트 디자인 프레임워크

#### 프롬프트 디자인

- 프롬프트 디자인 : 프롬프트 구조를 설계하는 일
  - 적절한 컨텍스트 제공 + 원하는 결과 추출을 위한 프롬프트 + 원하는 포맷의 출력을 위한 프롬프트
- 5가지 단계
  - 프롬프트 결과 설정
  - 프롬프트 평가 설계
  - 그라운딩 설계 및 평가
  - 프롬프트 디자인
  - 모니터링 및 개선

#### 프롬프트 디자인 프레임워크

- 프롬프트 디자인시 편리하게 생각할 수 있는 프레임워크를 만들어 둠

#### 프롬프트 구성 요소

- Role : 답변자로써 페르소나를 설정
  - 답변에 대한 배경 지식을 가지고 답하므로 더 높은 정확도로 답하게 됨
  - 예1) 당신은 법률 전문가입니다.
  - 예2) 당신은 영어 교사입니다.
- Audience : 답변의 대상이 되는 특정 인구, 그룹, 또는 개인의 페르소나
  - 예1) 초등학생을 위한 ...
  - 예2) 고급 요리사를 위한 ...
  - 예3) 트럼펫 초보자들을 위해 ...
- Knowledge(information) : 답변에 참고할 정보, 사용자의 질문에 해당하는 정보를 DB나 검색엔진 등에서 가져와 삽입하거나 유명한 정보 출처를 지정
  - 예) 위키피디아의 내용에 따라 ...
- Task : 수행해야 하는 특정 작업이나 목표
  - 예1) 500 단어로 자기 소개서를 작성해주세요.
  - 예2) 환경 보호를 위한 persuasive speech를 만들어 주세요.
  - 예3) 마케팅 전략을 개선하기 위한 제안을 제시해주세요.
- Policy(Rule) : 응답을 만들 때 따라야 하는 특정 정책이나 규칙 + Style + Constraint
  - 예1) 성격의 긍정적인 측면만을 강조하며 자기소개서를 작성해주세요.
  - 예2) 건설적인 피드백만 제공하면서 에세이를 평가해주세요.
  - 예3) 유머러스한 톤으로 ...
  - 예4) 공손하고 정중한 말투로 ..
  - 예5) 한 페이지 내로 ...
  - 예6) 140자 이내로 ... (딱 정확하게 맞춰주진 않음)
- Format : 응답이 따라야 하는 특정 형식이나 구조
  - 예1) JSON 형식으로 ...
  - 예2) 가사 형식으로 ...
- Examples : 원하는 응답의 예시를 제공

> 각 항목은 모두 존재해야하는 것은 아니며, 목적에 따라 조합하여 사용함

#### 프롬프트 개선

- 프롬프트를 구조적으로 만들면 LLM이 지시를 더 명확하게 이해함

```
context:
...

규칙:
...

User:...
Assistant:
```

> 위는 간략하게 나타낸 것이고 조금 보강해야할듯

## Chapter 2. 프롬프팅 테크닉 Top7

#### 1. Few-shot examples

- 모델에 몇 가지 예시를 제공하는 기법
- Zero-shot, One-shot, Few-shot 으로 나뉨
- 제약
  - 충분히 큰 모델에서만 유의미하게 작동
  - 산술 추론 문제에는 적합하지 않음
  - 정답을 정확히 주기보다 다양한 샘플을 주는 것이 중요
  - 일정 개수가 넘어가면 성능이 saturation 됨

#### 2. Chain-of-Thought

- LLM에게 이유에 대해서 설명하도록 만들어 답을 더 정확하게 생성하도록 만드는 기술
- 중간 추론 단계를 거치도록 하여, 복잡한 사고가 필요한 작업에 정확도를 향상 시키는 방법
- **답이 나오는 과정에 대한 설명한 예시를 보여주고**, 지시에 대한 답을 생성할 때 예시와 동일한 방식으로 그에 대한 과정을 설명하도록 만듦
- COT도 충분히 큰 모델에서 유의미하게 작동함
- Zero-shot COT : 예시를 제시하지 않고 "Let's think step by step" 문구를 제시해서 COT 예제를 제공하는 것과 같은 효과를 내는 기법
  - OpenAI Chat 형식은 기본적으로 Zero-shot COT가 적용되어 있음
- 어떤 경우는 오히려 성능이 떨어질 수 있어, 해당 문제를 풀기 위한 적절한 방법이 맞는지 여러 샘플로 확인 필요

#### 3. Self-Consistency

- 여러가지 방식의 COT를 제공하고, 이를 통해 다양한 추론 과정을 거친 다음에 그중에서 가장 많이 나온 일관된 답을 선택하는 COT의 확장 기술
- 예제를 보면 QA 세트에 여러가지 방법들을 제시하여 예시를 COT를 작성함. output을 여러개 출력한 다음 그 중 많이 나온 답을 선택함
- 논문에 따르면 20개 정도의 COT 샘플을 주는 것이 효과적임
- 역시 대규모 모델에서 잘 작동함
- 추론 경로를 최대한 다양하게 제공하므로 토큰 수를 많이 사용함
- 결과 취합을 위한 후처리도 필요함
- 아주 정확한 결과가 필요한 경우에만 사용

#### 4. Selection-Inference

- 복잡한 문제를 해결하기 위해서 여러 추론 단계를 연결하기 위한 기술
- 선택과 추론 사이를 번갈아가며 해석 가능한 원인과 결과의 추론 단계를 생성해서 최종 답변을 이끌어내는 방법(?)
- 컨텍스트에서 질문에 답할 수 있는 정보를 선택한 다음, 선택한 정보를 기반으로 답변을 하도록 만드는 방법

1. Selection

```
Context:
...

Question:
...

질문의 답에 필요한 내용을 Context에서 추출해서 나열하세요
```

2. Question

```
Selection의 내용에 기반해 Question에 대해 답하세요
```

> 논문에서는 Selection inference를 반복적으로 여러 번 사용하라고 함

#### 5. Least-to-Most

- 하나의 문제를 더 작은 여러 개의 하위 작업으로 분할하는 기법
- 어떤 주어진 문제를 풀려면 다음 문제를 풀어야합니다. 하면서 한 단계씩 반복적으로 진행하는 방법

```
Question:
...

이 문제의 답을 하기 위해 먼저 풀어야할 하위 질문을 하나 만들어 주세요.
```

- 위 답변을 다시 질문으로 넣고, 이런식으로 반복함
- 다른 기법들에 비해 굉장히 높은 성능을 보임

> Task를 분할하여 작은 문제로 나눠 해결하는 분할 정봉 방법으로 응용하여 Autonomous Agent 개발 등에 사용

#### 6. ReAct

- 실행 계획을 유도하고 추적해서 작업별로 실행할 액션을 선택하고 실행하는 기법
- 외부 API와 상호 작용하여 검색엔진을 통해 신뢰할 수 있는 정보를 사용하거나, 계산기나 이미지 생성 등의 도구를 사용
- 프롬프트에 어떤 상황에 어떤 도구를 사용할지 알려줌

> llm에 빌트인된 도구들이 있을까?

- 실제 툴을 사용해서 정보를 주입하지 않아도, 위키피디아 검색을 시뮬레이션 하는 것만으로 성능향상을 시킬 수 있음
- 실제 툴을 사용하도록 할 때는, 각 단계별로 끊어서 결과를 출력하도록 제어할 필요가 있음

#### 7. Self Evaluation

- llm이 생성한 결과를 llm이 평가하게 해서 오류를 잡거나 결과를 향상시키는 기법
- 사용처 : 데이터셋 생성 자동화, RLHF의 AI 피드백, 프롬프트 평가 자동화 등을 사용하여 데이터셋이나 LLM의 결과를 스스로 조정

```
9+10x3을 계산하세요

다음 포맷으로 답변하세요.
Answer:{number}
```

```
답변을 맞게 했는지 단계적으로 생각해보세요.
당신의 답변이 틀렸다면 틀린 이유를 설명하세요.
설명만 작성하세요. 그 외의 부가적인 말은 하지 마세요.
```

```
당신의 평가를 참고하여 처음 질문에 대한 답변을 다시 하세요.

다음 포맷으로 답변하세요.
Answer:{number}
```

- Self Evaluation은 구체적이 프레임워크가 존재하는 것은 아님
- AI가 스스로의 결과를 평가하고 향상시키는 방법이 가장 중요한 방법론 중 하나가 될 것으로 예상함

## Chapter 3. 프롬프팅 확장 테크닉

#### 1. Expert Prompting

- LLM에게 전문가로서 응답하도록 요청하는 방법
- 배경 지식을 암시적으로 이해하고 답변함으로써 성능이 크게 향상됨
- LLM에게 프롬프트/질문과 관련된 특정 분야의 전문가를 찾아달라고 요청하고, 제시 받은 전문가인 것처럼 질문에 응답하도록 하여 도메인이 정해지지 않은 서비스에도 제너럴하게 활용할 수 있음

#### 2. According to Wikipedia

- "Wikipedia를 참조헤서 답하세요" 라고 지시하는 것만으로도 높은 성능을 얻을 수 있는 방법
- LLM이 학습한 지식 베이스가 있다면, 해당 내용을 참조하라고 하는 것만으로 더 정확한 답변을 할 수 있음

#### 3. Generated knowledge Prompting

- 답변에 해당하는 지식을 먼저 생성하라고 하고, 그 뒤 생성한 지식을 바탕으로 답변을 생성하는 기법
- "According to Wikipedia"등의 기법과 마찬가지로 구체적인 지식을 바탕으로 답하게 함
- 단, 생성 AI 특성상 정확한 지식을 생성할 것이라는 보장이 없으므로, 생성 결과를 주의 깊게 평가 할 필요가 있음

#### 4. Retrieval Augmented Generation (RAG)

- 답변을 생성하기 전 사용자의 요청과 관련된 지식을 검색 컴포넌트에서 검색해와서, 해당 내용을 프롬프트의 컨텍스트로 제공하는 기법
- 답변의 정확도를 극도로 높이기 위한 가장 좋고 확실한 방법
- RAG는 프롬프트 엔지니어링의 필수적인 구성요소가 되었음
- 이에 따라 Vector Search가 매우 중요한 구성 요소로 자리 잡음
- 단순한 검색 뿐 아니라 복잡한 수식을 하는 수학 문제 풀이 엔진을 통해 결과를 생성해서 가져오는 등의 방법 또한 RAG라고 할 수 있음
- ChatGPT Plugin이 RAG의 극의라고 할 수 있음

> 1~4 기법은 예시를 제공하고 생각하게 만드는 기법임

#### 5. Tree-of-Thought

- 트리 구조로 답변을 생성해내면서, 중간 단계에서 진행 상황을 스스로 평가하여 생각 트리를 확장하고 조정하는 방법
- 생성한 결과와 평가를 통해 앞뒤로 생각을 체계적으로 탐색하여 매우 높은 수준의 사고를 할 수 있도록 함
- 매우 많은 생성단계를 거치므로 일반적으로 사용하기는 어려움
- 고도의 생성 전략이 필요한 경우 다른 기법들과 혼합해 사용하면 극도로 높은 성능을 기대할 수 있음

#### 6. Plan-and-Solve Prompting

- COT나 Self-Confidency 기법 사용시 답변이 잘못되는 가장 큰 문제는 중간 문제 풀이 단계가 누락되는 경우임
- 이러한 단계 누락의 오류를 해결하기 위한 기법
- 전체 작업을 더 작은 하위 작업으로 계획을 세우고, 그 계획에 따라 하위 작업을 수행하거나 평가하면서 전체 문제를 해결 하는 기법
- Least-to-Most가 풀어야할 문제를 단계적으로 생성해가면서 문제를 푸는 방식이라면
- plan-and-solve는 미리 풀어야 할 하위 문제를 모두 생성해두고 문제를 푼다는 것이 다름

#### 7. Automatic Prompt Engineer

- LLM으로 프롬프트를 자동 생성하는 기법
- 프롬프트에 `<INSERT>`라는 빈 칸을 만들고, 생성 결과를 함께 주면서 모델에게 `<INSERT>` 부분을 채우도록 하는 방법을 반복하는 기법
- 반복을 통해 `<INSERT>` 를 채울만한 답변을 여러 개 생성하고, 해당 프롬프트로 테스트 한 후 최종결과를 채점하여 가장 높은 점수를 받은 프롬프트를 사용
- 프롬프트를 처음부터 만들기 어려우니 기본 프롬프의를 작성하고 성능을 올리기 위한 파인튜닝의 개념으로 사용

> 5~7 기법은 전략을 짜고 스스로 평가하게 만드는 기법임

#### 기법들의 Key Point

1. 예시를 제공한다.
2. 생각을 많이 하게 만든다.
3. 문제 풀이 전략을 세우게 한다.
4. 스스로 평가한다.

## Chapter 4. 프롬프트 보안

#### LLM의 보안 취약점

1. Prompt Injections : 정교하게 제작된 프롬프트를 사용해 필터를 우회하거나 LLM을 조작하여 의도하지 않은 행동을 수행하게 만드는 방법
   - 프롬프트 분석을 미리 하고 실행하는 방법으로 예방
   - 100% 방어는 어려움
2. Data Leakage : LLM의 응답을 통해 민감한 정보, 독점 알고리즘, 또는 기타 기밀 세부사항을 실수로 공개
3. Inadequate Sandboxing : 외부 자원이나 민감한 시스템에 접근할 수 있는 LLM을 적절히 격리하지 못해 잠재적인 악용이 가능하게 되는 경우
4. Unauthorized Code Execution : 자연어 프롬프트를 통해 기본 시스템에서 악의적인 코드, 명령, 또는 행동을 실행
5. SSRF Vulnerabilities : 내부 서비스, API, DB와 같은 제한된 자원에 접근하거나 의도치 않은 요청을 수행하도록 악용
6. Overreliance on LLM-generated Content : 사람의 감독 없이 LLM에 과도하게 의존하면서 해로운 결과를 초래하게 되는 문제
7. Inadequate AI Alignment : 원치 않은 결과나 취약점을 초래하는 문제
8. Insufficient Access Controls : 인증을 제대로 구현하지 않아 비인증 사용자가 LLM과 상호작용하고 취약점을 악용할 수 있는 문제
9. Improper Error Handling : 오류 메시지나 디버깅 정보가 공개되어 민감한 정보나 시스템 세부사항 또는 잠재적 공격 경로를 노출하게 되는 문제
10. Training Data Poisoning : 학습 데이터나 미세 조정 절차를 악의적으로 조작하여 LLM의 취약점이나 백도어를 도입하는 공격
